{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Classifying handwritten digits with MNIST Dataset\n","metadata":{}},{"cell_type":"markdown","source":"In this notebook , I implemented a simple multilayer neural network from scratch using GradientDecent that can classify MNIST dataset handwritten digits instead of using an open source Python machine learning library.I have connected multiple neurons to a powerful NN architecture to solve complex problems such \nas handwritten digit recognition.\n\nBelow steps were applied through model build-up :\n\n- Download the MNIST Data Set\n- Normalize the Data to let algorithm behave more stable under GradientDecent optimization\n- Define (layer_number=2, hidden_neuron_number=50) NeuralNetMLP Class to implement forward and backward passes for execution.\n- Train the model with parameters num_epochs = 50 and minibatch_size = 100 and learning_rate = 0,1\n- Define mse loss and accuracy functions\n- Plot Accuracy value and Cost function.\n- Output 25 misclassified example those were predicted incorrectly in test set.\n","metadata":{}},{"cell_type":"markdown","source":"The MNIST dataset is publicly available at http://yann.lecun.com/exdb/mnist/ and consists of the following four parts:\n\n- Training set images: train-images-idx3-ubyte.gz (9.9 MB, 47 MB unzipped, 60,000 examples)\n- Training set labels: train-labels-idx1-ubyte.gz (29 KB, 60 KB unzipped, 60,000 labels)\n- Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 7.8 MB, 10,000 examples)\n- Test set labels: t10k-labels-idx1-ubyte.gz (5 KB, 10 KB unzipped, 10,000 labels)","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_openml\n\n\nX, y = fetch_openml('mnist_784', version=1, return_X_y=True)\nX = X.values\ny = y.astype(int).values\n\nprint(X.shape)\nprint(y.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-23T10:02:26.350878Z","iopub.execute_input":"2022-08-23T10:02:26.351461Z","iopub.status.idle":"2022-08-23T10:03:49.812830Z","shell.execute_reply.started":"2022-08-23T10:02:26.351336Z","shell.execute_reply":"2022-08-23T10:03:49.811436Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Normalize to [-1, 1] range:","metadata":{}},{"cell_type":"code","source":"X = ((X / 255.) - .5) * 2","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:04:52.873024Z","iopub.execute_input":"2022-08-23T10:04:52.874162Z","iopub.status.idle":"2022-08-23T10:04:53.315259Z","shell.execute_reply.started":"2022-08-23T10:04:52.874114Z","shell.execute_reply":"2022-08-23T10:04:53.313591Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Visualize the first digit of each class:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\nax = ax.flatten()\nfor i in range(10):\n    img = X[y == i][0].reshape(28, 28)\n    ax[i].imshow(img, cmap='Greys')\n\nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\n#plt.savefig('figures/11_4.png', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:05:17.358235Z","iopub.execute_input":"2022-08-23T10:05:17.358878Z","iopub.status.idle":"2022-08-23T10:05:18.676094Z","shell.execute_reply.started":"2022-08-23T10:05:17.358824Z","shell.execute_reply":"2022-08-23T10:05:18.674576Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Visualize 25 different versions of \"7\":\n","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True)\nax = ax.flatten()\nfor i in range(25):\n    img = X[y == 7][i].reshape(28, 28)\n    ax[i].imshow(img, cmap='Greys')\n\nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\n# plt.savefig('figures/11_5.png', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:05:53.210928Z","iopub.execute_input":"2022-08-23T10:05:53.211403Z","iopub.status.idle":"2022-08-23T10:05:56.264908Z","shell.execute_reply.started":"2022-08-23T10:05:53.211362Z","shell.execute_reply":"2022-08-23T10:05:56.263284Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_temp, X_test, y_temp, y_test = train_test_split(\n    X, y, test_size=10000, random_state=123, stratify=y)\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X_temp, y_temp, test_size=5000, random_state=123, stratify=y_temp)\n\n\n# optional to free up some memory by deleting non-used arrays:\ndel X_temp, y_temp, X, y","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:06:10.777612Z","iopub.execute_input":"2022-08-23T10:06:10.778077Z","iopub.status.idle":"2022-08-23T10:06:12.033993Z","shell.execute_reply.started":"2022-08-23T10:06:10.778040Z","shell.execute_reply":"2022-08-23T10:06:12.032657Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Implementing a multi-layer perceptron","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:08:19.279691Z","iopub.execute_input":"2022-08-23T10:08:19.280227Z","iopub.status.idle":"2022-08-23T10:08:19.285806Z","shell.execute_reply.started":"2022-08-23T10:08:19.280190Z","shell.execute_reply":"2022-08-23T10:08:19.284597Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"##########################\n### MODEL\n##########################\n\ndef sigmoid(z):                                        \n    return 1. / (1. + np.exp(-z))\n\n\ndef int_to_onehot(y, num_labels):\n\n    ary = np.zeros((y.shape[0], num_labels))\n    for i, val in enumerate(y):\n        ary[i, val] = 1\n\n    return ary\n\n\nclass NeuralNetMLP:\n\n    def __init__(self, num_features, num_hidden, num_classes, random_seed=123):\n        super().__init__()\n        \n        self.num_classes = num_classes\n        \n        # hidden\n        rng = np.random.RandomState(random_seed)\n        \n        self.weight_h = rng.normal(\n            loc=0.0, scale=0.1, size=(num_hidden, num_features))\n        self.bias_h = np.zeros(num_hidden)\n        \n        # output\n        self.weight_out = rng.normal(\n            loc=0.0, scale=0.1, size=(num_classes, num_hidden))\n        self.bias_out = np.zeros(num_classes)\n        \n    def forward(self, x):\n        # Hidden layer\n        # input dim: [n_examples, n_features] dot [n_hidden, n_features].T\n        # output dim: [n_examples, n_hidden]\n        z_h = np.dot(x, self.weight_h.T) + self.bias_h\n        a_h = sigmoid(z_h)\n\n        # Output layer\n        # input dim: [n_examples, n_hidden] dot [n_classes, n_hidden].T\n        # output dim: [n_examples, n_classes]\n        z_out = np.dot(a_h, self.weight_out.T) + self.bias_out\n        a_out = sigmoid(z_out)\n        return a_h, a_out\n\n    def backward(self, x, a_h, a_out, y):  \n    \n        #########################\n        ### Output layer weights\n        #########################\n        \n        # onehot encoding\n        y_onehot = int_to_onehot(y, self.num_classes)\n\n        # Part 1: dLoss/dOutWeights\n        ## = dLoss/dOutAct * dOutAct/dOutNet * dOutNet/dOutWeight\n        ## where DeltaOut = dLoss/dOutAct * dOutAct/dOutNet\n        ## for convenient re-use\n        \n        # input/output dim: [n_examples, n_classes]\n        d_loss__d_a_out = 2.*(a_out - y_onehot) / y.shape[0]\n\n        # input/output dim: [n_examples, n_classes]\n        d_a_out__d_z_out = a_out * (1. - a_out) # sigmoid derivative\n\n        # output dim: [n_examples, n_classes]\n        delta_out = d_loss__d_a_out * d_a_out__d_z_out # \"delta (rule) placeholder\"\n\n        # gradient for output weights\n        \n        # [n_examples, n_hidden]\n        d_z_out__dw_out = a_h\n        \n        # input dim: [n_classes, n_examples] dot [n_examples, n_hidden]\n        # output dim: [n_classes, n_hidden]\n        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n        d_loss__db_out = np.sum(delta_out, axis=0)\n        \n\n        #################################        \n        # Part 2: dLoss/dHiddenWeights\n        ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet * dHiddenNet/dWeight\n        \n        # [n_classes, n_hidden]\n        d_z_out__a_h = self.weight_out\n        \n        # output dim: [n_examples, n_hidden]\n        d_loss__a_h = np.dot(delta_out, d_z_out__a_h)\n        \n        # [n_examples, n_hidden]\n        d_a_h__d_z_h = a_h * (1. - a_h) # sigmoid derivative\n        \n        # [n_examples, n_features]\n        d_z_h__d_w_h = x\n        \n        # output dim: [n_hidden, n_features]\n        d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h)\n        d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0)\n\n        return (d_loss__dw_out, d_loss__db_out, \n                d_loss__d_w_h, d_loss__d_b_h)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:08:37.029565Z","iopub.execute_input":"2022-08-23T10:08:37.029986Z","iopub.status.idle":"2022-08-23T10:08:37.046501Z","shell.execute_reply.started":"2022-08-23T10:08:37.029949Z","shell.execute_reply":"2022-08-23T10:08:37.045034Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = NeuralNetMLP(num_features=28*28,\n                     num_hidden=50,\n                     num_classes=10)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:08:50.892091Z","iopub.execute_input":"2022-08-23T10:08:50.892586Z","iopub.status.idle":"2022-08-23T10:08:50.902154Z","shell.execute_reply.started":"2022-08-23T10:08:50.892547Z","shell.execute_reply":"2022-08-23T10:08:50.900480Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Coding the neural network training loop\n","metadata":{}},{"cell_type":"markdown","source":"Defining data loaders:\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nnum_epochs = 50\nminibatch_size = 100\n\n\ndef minibatch_generator(X, y, minibatch_size):\n    indices = np.arange(X.shape[0])\n    np.random.shuffle(indices)\n\n    for start_idx in range(0, indices.shape[0] - minibatch_size \n                           + 1, minibatch_size):\n        batch_idx = indices[start_idx:start_idx + minibatch_size]\n        \n        yield X[batch_idx], y[batch_idx]\n\n        \n# iterate over training epochs\nfor i in range(num_epochs):\n\n    # iterate over minibatches\n    minibatch_gen = minibatch_generator(\n        X_train, y_train, minibatch_size)\n    \n    for X_train_mini, y_train_mini in minibatch_gen:\n\n        break\n        \n    break\n    \nprint(X_train_mini.shape)\nprint(y_train_mini.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:09:59.588951Z","iopub.execute_input":"2022-08-23T10:09:59.589443Z","iopub.status.idle":"2022-08-23T10:09:59.604374Z","shell.execute_reply.started":"2022-08-23T10:09:59.589402Z","shell.execute_reply":"2022-08-23T10:09:59.603006Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def mse_loss(targets, probas, num_labels=10):\n    onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n    return np.mean((onehot_targets - probas)**2)\n\n\ndef accuracy(targets, predicted_labels):\n    return np.mean(predicted_labels == targets) \n\n\n_, probas = model.forward(X_valid)\nmse = mse_loss(y_valid, probas)\n\npredicted_labels = np.argmax(probas, axis=1)\nacc = accuracy(y_valid, predicted_labels)\n\nprint(f'Initial validation MSE: {mse:.1f}')\nprint(f'Initial validation accuracy: {acc*100:.1f}%')","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:10:22.437309Z","iopub.execute_input":"2022-08-23T10:10:22.437927Z","iopub.status.idle":"2022-08-23T10:10:22.514234Z","shell.execute_reply.started":"2022-08-23T10:10:22.437875Z","shell.execute_reply":"2022-08-23T10:10:22.512538Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def compute_mse_and_acc(nnet, X, y, num_labels=10, minibatch_size=100):\n    mse, correct_pred, num_examples = 0., 0, 0\n    minibatch_gen = minibatch_generator(X, y, minibatch_size)\n        \n    for i, (features, targets) in enumerate(minibatch_gen):\n\n        _, probas = nnet.forward(features)\n        predicted_labels = np.argmax(probas, axis=1)\n        \n        onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n        loss = np.mean((onehot_targets - probas)**2)\n        correct_pred += (predicted_labels == targets).sum()\n        \n        num_examples += targets.shape[0]\n        mse += loss\n\n    mse = mse/i\n    acc = correct_pred/num_examples\n    return mse, acc","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:10:43.981604Z","iopub.execute_input":"2022-08-23T10:10:43.983173Z","iopub.status.idle":"2022-08-23T10:10:43.994341Z","shell.execute_reply.started":"2022-08-23T10:10:43.983123Z","shell.execute_reply":"2022-08-23T10:10:43.993279Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"mse, acc = compute_mse_and_acc(model, X_valid, y_valid)\nprint(f'Initial valid MSE: {mse:.1f}')\nprint(f'Initial valid accuracy: {acc*100:.1f}%')","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:11:00.983111Z","iopub.execute_input":"2022-08-23T10:11:00.983505Z","iopub.status.idle":"2022-08-23T10:11:01.045799Z","shell.execute_reply.started":"2022-08-23T10:11:00.983472Z","shell.execute_reply":"2022-08-23T10:11:01.044285Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train(model, X_train, y_train, X_valid, y_valid, num_epochs,\n          learning_rate=0.1):\n    \n    epoch_loss = []\n    epoch_train_acc = []\n    epoch_valid_acc = []\n    \n    for e in range(num_epochs):\n\n        # iterate over minibatches\n        minibatch_gen = minibatch_generator(\n            X_train, y_train, minibatch_size)\n\n        for X_train_mini, y_train_mini in minibatch_gen:\n            \n            #### Compute outputs ####\n            a_h, a_out = model.forward(X_train_mini)\n\n            #### Compute gradients ####\n            d_loss__d_w_out, d_loss__d_b_out, d_loss__d_w_h, d_loss__d_b_h = \\\n                model.backward(X_train_mini, a_h, a_out, y_train_mini)\n\n            #### Update weights ####\n            model.weight_h -= learning_rate * d_loss__d_w_h\n            model.bias_h -= learning_rate * d_loss__d_b_h\n            model.weight_out -= learning_rate * d_loss__d_w_out\n            model.bias_out -= learning_rate * d_loss__d_b_out\n        \n        #### Epoch Logging ####        \n        train_mse, train_acc = compute_mse_and_acc(model, X_train, y_train)\n        valid_mse, valid_acc = compute_mse_and_acc(model, X_valid, y_valid)\n        train_acc, valid_acc = train_acc*100, valid_acc*100\n        epoch_train_acc.append(train_acc)\n        epoch_valid_acc.append(valid_acc)\n        epoch_loss.append(train_mse)\n        print(f'Epoch: {e+1:03d}/{num_epochs:03d} '\n              f'| Train MSE: {train_mse:.2f} '\n              f'| Train Acc: {train_acc:.2f}% '\n              f'| Valid Acc: {valid_acc:.2f}%')\n\n    return epoch_loss, epoch_train_acc, epoch_valid_acc","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:11:15.557268Z","iopub.execute_input":"2022-08-23T10:11:15.558411Z","iopub.status.idle":"2022-08-23T10:11:15.569800Z","shell.execute_reply.started":"2022-08-23T10:11:15.558359Z","shell.execute_reply":"2022-08-23T10:11:15.568432Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"np.random.seed(123) # for the training set shuffling\n\nepoch_loss, epoch_train_acc, epoch_valid_acc = train(\n    model, X_train, y_train, X_valid, y_valid,\n    num_epochs=50, learning_rate=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:11:29.149648Z","iopub.execute_input":"2022-08-23T10:11:29.150109Z","iopub.status.idle":"2022-08-23T10:12:50.214488Z","shell.execute_reply.started":"2022-08-23T10:11:29.150072Z","shell.execute_reply":"2022-08-23T10:12:50.213098Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"We can see that the test accuracy is very close to the validation set accuracy corresponding to the last epoch (94.74%), which I reported during the training above. Moreover, the respective training accuracy is only minimally higher at 95.59%, reaffirming that the model only **slightly** overfits the training data","metadata":{}},{"cell_type":"markdown","source":"## Evaluating the neural network performance\n","metadata":{}},{"cell_type":"code","source":"plt.plot(range(len(epoch_loss)), epoch_loss)\nplt.ylabel('Mean squared error')\nplt.xlabel('Epoch')\n#plt.savefig('figures/11_07.png', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:14:12.892920Z","iopub.execute_input":"2022-08-23T10:14:12.893514Z","iopub.status.idle":"2022-08-23T10:14:13.090541Z","shell.execute_reply.started":"2022-08-23T10:14:12.893469Z","shell.execute_reply":"2022-08-23T10:14:13.089371Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(len(epoch_train_acc)), epoch_train_acc,\n         label='Training')\nplt.plot(range(len(epoch_valid_acc)), epoch_valid_acc,\n         label='Validation')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(loc='lower right')\n#plt.savefig('figures/11_08.png', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:14:17.285933Z","iopub.execute_input":"2022-08-23T10:14:17.286419Z","iopub.status.idle":"2022-08-23T10:14:17.507244Z","shell.execute_reply.started":"2022-08-23T10:14:17.286380Z","shell.execute_reply":"2022-08-23T10:14:17.505658Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test_mse, test_acc = compute_mse_and_acc(model, X_test, y_test)\nprint(f'Test accuracy: {test_acc*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:14:29.030530Z","iopub.execute_input":"2022-08-23T10:14:29.030955Z","iopub.status.idle":"2022-08-23T10:14:29.146832Z","shell.execute_reply.started":"2022-08-23T10:14:29.030919Z","shell.execute_reply":"2022-08-23T10:14:29.145467Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"**Plot failure cases:**","metadata":{}},{"cell_type":"code","source":"X_test_subset = X_test[:1000, :]\ny_test_subset = y_test[:1000]\n\n_, probas = model.forward(X_test_subset)\ntest_pred = np.argmax(probas, axis=1)\n\nmisclassified_images = X_test_subset[y_test_subset != test_pred][:25]\nmisclassified_labels = test_pred[y_test_subset != test_pred][:25]\ncorrect_labels = y_test_subset[y_test_subset != test_pred][:25]","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:14:34.516854Z","iopub.execute_input":"2022-08-23T10:14:34.518262Z","iopub.status.idle":"2022-08-23T10:14:34.540972Z","shell.execute_reply.started":"2022-08-23T10:14:34.518217Z","shell.execute_reply":"2022-08-23T10:14:34.539462Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Missclassified 25 items","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=5, ncols=5, \n                       sharex=True, sharey=True, figsize=(8, 8))\nax = ax.flatten()\nfor i in range(25):\n    img = misclassified_images[i].reshape(28, 28)\n    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n    ax[i].set_title(f'{i+1}) '\n                    f'True: {correct_labels[i]}\\n'\n                    f' Predicted: {misclassified_labels[i]}')\n\nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\n#plt.savefig('figures/11_09.png', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-23T10:14:38.411591Z","iopub.execute_input":"2022-08-23T10:14:38.413189Z","iopub.status.idle":"2022-08-23T10:14:40.336035Z","shell.execute_reply.started":"2022-08-23T10:14:38.413122Z","shell.execute_reply":"2022-08-23T10:14:40.334118Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Thank you","metadata":{}}]}